{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c6daba3253244d2dab9f758f4f29e18f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18b3c2d494fc4990846b5b6c085ed7fd",
              "IPY_MODEL_687afc222ab74f9f9ed5a4fcdf45c55e",
              "IPY_MODEL_5f8bfc96b17e4dd594016bdab1c7f7c7"
            ],
            "layout": "IPY_MODEL_8f174b40bd49437fa346913ecdbef04f"
          }
        },
        "18b3c2d494fc4990846b5b6c085ed7fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_006e19e4affd434e8305fe57f1a7c36c",
            "placeholder": "​",
            "style": "IPY_MODEL_45b8503dcbda41df8927180b8ea25933",
            "value": "Map: 100%"
          }
        },
        "687afc222ab74f9f9ed5a4fcdf45c55e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa8f5086e46b49998d8349b9e93844f2",
            "max": 26263,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf51a35edabb4effa7d4be1e13bc7994",
            "value": 26263
          }
        },
        "5f8bfc96b17e4dd594016bdab1c7f7c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_699b9f07558f405daed87fdd4b0677df",
            "placeholder": "​",
            "style": "IPY_MODEL_b9b915c0f06c4b61a28b07618caad60e",
            "value": " 26263/26263 [01:27&lt;00:00, 276.84 examples/s]"
          }
        },
        "8f174b40bd49437fa346913ecdbef04f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "006e19e4affd434e8305fe57f1a7c36c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45b8503dcbda41df8927180b8ea25933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa8f5086e46b49998d8349b9e93844f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf51a35edabb4effa7d4be1e13bc7994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "699b9f07558f405daed87fdd4b0677df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9b915c0f06c4b61a28b07618caad60e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ed206c55f3a4a338b51be38b89a0d6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87ac6aba356b4defba75d6fc82f3897d",
              "IPY_MODEL_2ff3207c83e3423aafa823e8a1ae7834",
              "IPY_MODEL_10daafbe8df648b5a271804d6be50a7c"
            ],
            "layout": "IPY_MODEL_8913366bdfbc464885f221c88ac04de6"
          }
        },
        "87ac6aba356b4defba75d6fc82f3897d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44886bb02ca448d49451101437cc878a",
            "placeholder": "​",
            "style": "IPY_MODEL_0dc587ca4451436998acd8ff5cb90717",
            "value": "Map: 100%"
          }
        },
        "2ff3207c83e3423aafa823e8a1ae7834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53f2d6d0aa21411fa9e3eec43dc85a66",
            "max": 11256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f86a47b6181544158836317b5188fb43",
            "value": 11256
          }
        },
        "10daafbe8df648b5a271804d6be50a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7bf0180c8e7460a81d7ad295ce97e44",
            "placeholder": "​",
            "style": "IPY_MODEL_fa8d2aac8f4c481093afef2139c8f085",
            "value": " 11256/11256 [00:35&lt;00:00, 318.95 examples/s]"
          }
        },
        "8913366bdfbc464885f221c88ac04de6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44886bb02ca448d49451101437cc878a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dc587ca4451436998acd8ff5cb90717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53f2d6d0aa21411fa9e3eec43dc85a66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f86a47b6181544158836317b5188fb43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7bf0180c8e7460a81d7ad295ce97e44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa8d2aac8f4c481093afef2139c8f085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30627,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliasharf123/arabic-summarization-with-araBert/blob/main/arabic_summarization_with_araBert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arabic Summerization content With AraBert"
      ],
      "metadata": {
        "id": "1DIxxDC-adiD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies  "
      ],
      "metadata": {
        "id": "2N9piC8mbFsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install sentencepiece"
      ],
      "metadata": {
        "id": "DDlEqDzRj55p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0d2d569-c3d6-4b8d-c85c-b4b6af62474b",
        "execution": {
          "iopub.status.busy": "2023-12-28T13:49:07.475376Z",
          "iopub.execute_input": "2023-12-28T13:49:07.475715Z",
          "iopub.status.idle": "2023-12-28T13:49:20.499742Z",
          "shell.execute_reply.started": "2023-12-28T13:49:07.475691Z",
          "shell.execute_reply": "2023-12-28T13:49:20.498507Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.1.99)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U"
      ],
      "metadata": {
        "id": "Mz5GCfi-sVit",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6d2b9ec-c97f-469e-c3ac-fd043f6a4e2b",
        "execution": {
          "iopub.status.busy": "2023-12-28T13:49:20.502379Z",
          "iopub.execute_input": "2023-12-28T13:49:20.502808Z",
          "iopub.status.idle": "2023-12-28T13:49:32.431230Z",
          "shell.execute_reply.started": "2023-12-28T13:49:20.502768Z",
          "shell.execute_reply": "2023-12-28T13:49:32.430054Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.25.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.19.4)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2023.12.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "id": "jCdIImtVsk3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c30155f4-72f0-49f5-a502-1942c947e92c",
        "execution": {
          "iopub.status.busy": "2023-12-28T13:49:32.432679Z",
          "iopub.execute_input": "2023-12-28T13:49:32.433018Z",
          "iopub.status.idle": "2023-12-28T13:49:44.278125Z",
          "shell.execute_reply.started": "2023-12-28T13:49:32.432991Z",
          "shell.execute_reply": "2023-12-28T13:49:44.276763Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.36.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.19.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.15.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\nRequirement already satisfied: torch!=1.12.0,>=1.10 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.0.0)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.25.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.0.9)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2023.11.17)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers\n",
        "! pip install datasets\n",
        "! pip install rouge_score\n",
        "! pip install wandb"
      ],
      "metadata": {
        "id": "5Pa7bPJAjz_j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c06afa8-ee04-4c50-e56e-bb08a943d6a7",
        "execution": {
          "iopub.status.busy": "2023-12-28T13:49:44.281502Z",
          "iopub.execute_input": "2023-12-28T13:49:44.282005Z",
          "iopub.status.idle": "2023-12-28T13:50:33.938980Z",
          "shell.execute_reply.started": "2023-12-28T13:49:44.281968Z",
          "shell.execute_reply": "2023-12-28T13:50:33.937813Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.36.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.24.3)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.12.2)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.5)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.19.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.24.3)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24932 sha256=7a55d08b6311b97de90fe97f60663318b7e5d2dccd1cdfdab88af0e6f7a3ec82\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.1)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.32)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.39.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (68.1.2)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge\n"
      ],
      "metadata": {
        "id": "_rUsRA8dEM-0",
        "execution": {
          "iopub.status.busy": "2023-12-28T13:50:33.940398Z",
          "iopub.execute_input": "2023-12-28T13:50:33.940707Z",
          "iopub.status.idle": "2023-12-28T13:50:45.826962Z",
          "shell.execute_reply.started": "2023-12-28T13:50:33.940679Z",
          "shell.execute_reply": "2023-12-28T13:50:45.825992Z"
        },
        "trusted": true,
        "outputId": "725a3aa6-7e6b-41b9-9962-4e97efe3aa5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting rouge\n  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\nInstalling collected packages: rouge\nSuccessfully installed rouge-1.0.1\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T13:50:45.828368Z",
          "iopub.execute_input": "2023-12-28T13:50:45.828676Z",
          "iopub.status.idle": "2023-12-28T13:50:57.697684Z",
          "shell.execute_reply.started": "2023-12-28T13:50:45.828649Z",
          "shell.execute_reply": "2023-12-28T13:50:57.696394Z"
        },
        "trusted": true,
        "id": "YonKyaFZlrvc",
        "outputId": "745de15e-1aad-4e83-b3f9-b0be2cf31d5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: rouge_score in /opt/conda/lib/python3.10/site-packages (0.1.2)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.24.3)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "H16EGvF7bMoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "import torch\n",
        "import numpy as np\n",
        "import datasets\n",
        "from transformers import (\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoTokenizer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        ")\n",
        "import pandas as pd\n",
        "from rouge import Rouge\n",
        "from prettytable import PrettyTable\n",
        "from tabulate import tabulate\n",
        "import nltk\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "HPKHy-gCcM7h",
        "execution": {
          "iopub.status.busy": "2023-12-28T13:50:57.699479Z",
          "iopub.execute_input": "2023-12-28T13:50:57.700421Z",
          "iopub.status.idle": "2023-12-28T13:50:58.293343Z",
          "shell.execute_reply.started": "2023-12-28T13:50:57.700381Z",
          "shell.execute_reply": "2023-12-28T13:50:58.292276Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initilize the AraBert model from hugging face"
      ],
      "metadata": {
        "id": "ca5C8S5WcT-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a mode name\n",
        "model_name=\"abdalrahmanshahrour/arabartsummarization\"\n",
        "\n",
        "# Get a pretrained model\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# Get it's Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "imfAcJ6xpOud",
        "execution": {
          "iopub.status.busy": "2023-12-28T13:50:58.294559Z",
          "iopub.execute_input": "2023-12-28T13:50:58.294881Z",
          "iopub.status.idle": "2023-12-28T13:51:03.332060Z",
          "shell.execute_reply.started": "2023-12-28T13:50:58.294854Z",
          "shell.execute_reply": "2023-12-28T13:51:03.330979Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "ed8d5e252ab847d5945bdb330a34de1a",
            "e5614214db08474b9a40d47382779922",
            "a3798119775d49f5895ff9b5241c08bd",
            "22fc080b74474dc7885588b1ffe1bf37",
            "69370bf57e644aa1998839cdbee62228",
            "7fc3a61c9edf48a2b202062041323ace"
          ]
        },
        "outputId": "4fabd87d-717c-43e8-990b-fe1bfc0df5ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/1.48k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed8d5e252ab847d5945bdb330a34de1a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model.bin:   0%|          | 0.00/557M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5614214db08474b9a40d47382779922"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3798119775d49f5895ff9b5241c08bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "sentencepiece.bpe.model:   0%|          | 0.00/1.32M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22fc080b74474dc7885588b1ffe1bf37"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/3.78M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69370bf57e644aa1998839cdbee62228"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/279 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7fc3a61c9edf48a2b202062041323ace"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show a model configuration"
      ],
      "metadata": {
        "id": "wZqAhE7Id_Qz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming model.config is a dictionary\n",
        "model_config_dict = model.config.to_dict()\n",
        "\n",
        "# Create a PrettyTable instance\n",
        "table = PrettyTable()\n",
        "\n",
        "# Add columns\n",
        "table.field_names = [\"Parameter\", \"Value\"]\n",
        "\n",
        "# Add rows\n",
        "for parameter, value in model_config_dict.items():\n",
        "    table.add_row([parameter, value])\n",
        "\n",
        "# Print the table\n",
        "print(table)"
      ],
      "metadata": {
        "id": "KzkaP0hxeu9Z",
        "execution": {
          "iopub.status.busy": "2023-12-28T13:51:03.333356Z",
          "iopub.execute_input": "2023-12-28T13:51:03.333664Z",
          "iopub.status.idle": "2023-12-28T13:51:03.349550Z",
          "shell.execute_reply.started": "2023-12-28T13:51:03.333638Z",
          "shell.execute_reply": "2023-12-28T13:51:03.348411Z"
        },
        "trusted": true,
        "outputId": "98d706fb-4435-4ec9-cdcb-9197c2452ce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "+----------------------------------+--------------------------------------------+\n|            Parameter             |                   Value                    |\n+----------------------------------+--------------------------------------------+\n|            vocab_size            |                   50002                    |\n|     max_position_embeddings      |                    1024                    |\n|             d_model              |                    768                     |\n|         encoder_ffn_dim          |                    3072                    |\n|          encoder_layers          |                     6                      |\n|     encoder_attention_heads      |                     12                     |\n|         decoder_ffn_dim          |                    3072                    |\n|          decoder_layers          |                     6                      |\n|     decoder_attention_heads      |                     12                     |\n|             dropout              |                    0.1                     |\n|        attention_dropout         |                    0.1                     |\n|        activation_dropout        |                    0.1                     |\n|       activation_function        |                    gelu                    |\n|             init_std             |                    0.02                    |\n|        encoder_layerdrop         |                    0.0                     |\n|        decoder_layerdrop         |                    0.0                     |\n|        classifier_dropout        |                    0.0                     |\n|            use_cache             |                    True                    |\n|        num_hidden_layers         |                     6                      |\n|         scale_embedding          |                   False                    |\n|           return_dict            |                    True                    |\n|       output_hidden_states       |                   False                    |\n|        output_attentions         |                   False                    |\n|           torchscript            |                   False                    |\n|           torch_dtype            |                  float32                   |\n|           use_bfloat16           |                   False                    |\n|          tf_legacy_loss          |                   False                    |\n|           pruned_heads           |                     {}                     |\n|       tie_word_embeddings        |                    True                    |\n|        is_encoder_decoder        |                    True                    |\n|            is_decoder            |                   False                    |\n|   cross_attention_hidden_size    |                    None                    |\n|       add_cross_attention        |                   False                    |\n|       tie_encoder_decoder        |                   False                    |\n|            max_length            |                     20                     |\n|            min_length            |                     0                      |\n|            do_sample             |                   False                    |\n|          early_stopping          |                    True                    |\n|            num_beams             |                     4                      |\n|         num_beam_groups          |                     1                      |\n|        diversity_penalty         |                    0.0                     |\n|           temperature            |                    1.0                     |\n|              top_k               |                     50                     |\n|              top_p               |                    1.0                     |\n|            typical_p             |                    1.0                     |\n|        repetition_penalty        |                    1.0                     |\n|          length_penalty          |                    1.0                     |\n|       no_repeat_ngram_size       |                     3                      |\n|   encoder_no_repeat_ngram_size   |                     0                      |\n|          bad_words_ids           |                    None                    |\n|       num_return_sequences       |                     1                      |\n|     chunk_size_feed_forward      |                     0                      |\n|          output_scores           |                   False                    |\n|     return_dict_in_generate      |                   False                    |\n|       forced_bos_token_id        |                    None                    |\n|       forced_eos_token_id        |                     2                      |\n|      remove_invalid_values       |                   False                    |\n| exponential_decay_length_penalty |                    None                    |\n|         suppress_tokens          |                    None                    |\n|      begin_suppress_tokens       |                    None                    |\n|          architectures           |     ['MBartForConditionalGeneration']      |\n|         finetuning_task          |                    None                    |\n|             id2label             | {0: 'LABEL_0', 1: 'LABEL_1', 2: 'LABEL_2'} |\n|             label2id             | {'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2} |\n|         tokenizer_class          |              BarthezTokenizer              |\n|              prefix              |                    None                    |\n|           bos_token_id           |                     0                      |\n|           pad_token_id           |                     1                      |\n|           eos_token_id           |                     2                      |\n|           sep_token_id           |                    None                    |\n|      decoder_start_token_id      |                     2                      |\n|       task_specific_params       |                    None                    |\n|           problem_type           |                    None                    |\n|          _name_or_path           |  abdalrahmanshahrour/arabartsummarization  |\n|       transformers_version       |                   4.36.0                   |\n|         add_bias_logits          |                   False                    |\n|       add_final_layer_norm       |                    True                    |\n|         classif_dropout          |                    0.1                     |\n|    do_blenderbot_90_layernorm    |                   False                    |\n|       extra_pos_embeddings       |                     2                      |\n| force_bos_token_to_be_generated  |                   False                    |\n|      gradient_checkpointing      |                   False                    |\n|            model_type            |                   mbart                    |\n|         normalize_before         |                    True                    |\n|       normalize_embedding        |                    True                    |\n|    static_position_embeddings    |                   False                    |\n+----------------------------------+--------------------------------------------+\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load arabic XL-Sum dataset in hugging face"
      ],
      "metadata": {
        "id": "SZZ4AtykfaYl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load dataset"
      ],
      "metadata": {
        "id": "rXvETmgdf11d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.load_dataset(\"csebuetnlp/xlsum\", name=\"arabic\", split=\"train\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175,
          "referenced_widgets": [
            "3ee5b79676574ef6a6deffe6e08ac461",
            "262b6879bbe04a51adb5de726602c7c2",
            ""
          ]
        },
        "id": "r790Nd_Y1Jma",
        "outputId": "2f500ead-d1fc-449c-ad51-4e0e3b5d7af0",
        "execution": {
          "iopub.status.busy": "2023-12-28T13:51:03.353423Z",
          "iopub.execute_input": "2023-12-28T13:51:03.353763Z",
          "iopub.status.idle": "2023-12-28T13:51:22.647477Z",
          "shell.execute_reply.started": "2023-12-28T13:51:03.353709Z",
          "shell.execute_reply": "2023-12-28T13:51:22.646535Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script:   0%|          | 0.00/4.55k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ee5b79676574ef6a6deffe6e08ac461"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Downloading and preparing dataset xlsum/arabic to /root/.cache/huggingface/datasets/csebuetnlp___xlsum/arabic/2.0.0/518ab0af76048660bcc2240ca6e8692a977c80e384ffb18fdddebaca6daebdce...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/44.9M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "262b6879bbe04a51adb5de726602c7c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating validation split: 0 examples [00:00, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Dataset xlsum downloaded and prepared to /root/.cache/huggingface/datasets/csebuetnlp___xlsum/arabic/2.0.0/518ab0af76048660bcc2240ca6e8692a977c80e384ffb18fdddebaca6daebdce. Subsequent calls will reuse this data.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show dataset"
      ],
      "metadata": {
        "id": "00wSmm2YgA7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the dataset to a pandas DataFrame\n",
        "df = pd.DataFrame(dataset)\n",
        "\n",
        "# Display the dataset structure\n",
        "print(\"Dataset Structure:\")\n",
        "print(\"------------------\")\n",
        "print(df.info())\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "num_rows_to_display = 5\n",
        "print(\"\\nFirst Few Rows of the Dataset:\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "K3-EJulWgehZ",
        "outputId": "efb43f72-6058-40ed-c719-28f6d5367602",
        "execution": {
          "iopub.status.busy": "2023-12-28T13:51:22.649073Z",
          "iopub.execute_input": "2023-12-28T13:51:22.649476Z",
          "iopub.status.idle": "2023-12-28T13:51:26.628910Z",
          "shell.execute_reply.started": "2023-12-28T13:51:22.649441Z",
          "shell.execute_reply": "2023-12-28T13:51:26.628011Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Dataset Structure:\n------------------\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 37519 entries, 0 to 37518\nData columns (total 5 columns):\n #   Column   Non-Null Count  Dtype \n---  ------   --------------  ----- \n 0   id       37519 non-null  object\n 1   url      37519 non-null  object\n 2   title    37519 non-null  object\n 3   summary  37519 non-null  object\n 4   text     37519 non-null  object\ndtypes: object(5)\nmemory usage: 1.4+ MB\nNone\n\nFirst Few Rows of the Dataset:\n",
          "output_type": "stream"
        },
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                        id  \\\n0  140323_russian_troops_crimea_naval_base   \n1                    130528_egypt_nile_dam   \n2                           world-47242349   \n3                        vert-cul-55078328   \n4                     141023_yemen_hodeida   \n\n                                                 url  \\\n0  https://www.bbc.com/arabic/worldnews/2014/03/1...   \n1  https://www.bbc.com/arabic/middleeast/2013/05/...   \n2          https://www.bbc.com/arabic/world-47242349   \n3       https://www.bbc.com/arabic/vert-cul-55078328   \n4  https://www.bbc.com/arabic/middleeast/2014/10/...   \n\n                                               title  \\\n0           القوات الأوكرانية تبدأ الانسحاب من القرم   \n1    هل يفرض سد النهضة الإثيوبي واقعا جديدا على مصر؟   \n2  تعرف على منطقة كشمير التي تسببت بحربين بين اله...   \n3  ماذا تعرف عن العالم الخفي للمعابد اليابانية ال...   \n4  اشتباك بين الحوثيين و\"الحراك التهامي\" في الحدي...   \n\n                                             summary  \\\n0  بدأت القوات الأوكرانية الانسحاب من شبه جزيرة ا...   \n1  \"هل سيتم تغيير العبارة الشهيرة للمؤرخ اليوناني...   \n2  قالت الشرطة في القطاع الهندي من إقليم كشمير إن...   \n3  في عام 816، تجول راهب يدعى كوكاي، في المنحدرات...   \n4  أكد مصدر في \"الحراك التهامي\" لأبناء محافظة الح...   \n\n                                                text  \n0  وكان الرئيس الأوكراني المؤقت، الكسندر تورتشينو...  \n1  بحلول عام 2050 ستحتاج مصر إلى 21 مليار متر مكع...  \n2  وذكرت وكالة الأنباء المحلية (جي.إن.إس) أن جماع...  \n3  ووقع اختياره على واد عمقه 800 متر محاط بثماني ...  \n4  مسلح حوثي في إب وقال المصدر إن المسلحين الحوثي...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>url</th>\n      <th>title</th>\n      <th>summary</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>140323_russian_troops_crimea_naval_base</td>\n      <td>https://www.bbc.com/arabic/worldnews/2014/03/1...</td>\n      <td>القوات الأوكرانية تبدأ الانسحاب من القرم</td>\n      <td>بدأت القوات الأوكرانية الانسحاب من شبه جزيرة ا...</td>\n      <td>وكان الرئيس الأوكراني المؤقت، الكسندر تورتشينو...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>130528_egypt_nile_dam</td>\n      <td>https://www.bbc.com/arabic/middleeast/2013/05/...</td>\n      <td>هل يفرض سد النهضة الإثيوبي واقعا جديدا على مصر؟</td>\n      <td>\"هل سيتم تغيير العبارة الشهيرة للمؤرخ اليوناني...</td>\n      <td>بحلول عام 2050 ستحتاج مصر إلى 21 مليار متر مكع...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>world-47242349</td>\n      <td>https://www.bbc.com/arabic/world-47242349</td>\n      <td>تعرف على منطقة كشمير التي تسببت بحربين بين اله...</td>\n      <td>قالت الشرطة في القطاع الهندي من إقليم كشمير إن...</td>\n      <td>وذكرت وكالة الأنباء المحلية (جي.إن.إس) أن جماع...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>vert-cul-55078328</td>\n      <td>https://www.bbc.com/arabic/vert-cul-55078328</td>\n      <td>ماذا تعرف عن العالم الخفي للمعابد اليابانية ال...</td>\n      <td>في عام 816، تجول راهب يدعى كوكاي، في المنحدرات...</td>\n      <td>ووقع اختياره على واد عمقه 800 متر محاط بثماني ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>141023_yemen_hodeida</td>\n      <td>https://www.bbc.com/arabic/middleeast/2014/10/...</td>\n      <td>اشتباك بين الحوثيين و\"الحراك التهامي\" في الحدي...</td>\n      <td>أكد مصدر في \"الحراك التهامي\" لأبناء محافظة الح...</td>\n      <td>مسلح حوثي في إب وقال المصدر إن المسلحين الحوثي...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepocess the Dataset\n"
      ],
      "metadata": {
        "id": "yoq7bI6mf7HK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove the not wanted columns"
      ],
      "metadata": {
        "id": "HZLFB57ZhiAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.remove_columns([\"id\",\"url\",\"title\"])"
      ],
      "metadata": {
        "id": "-0tQcyPVomK7",
        "execution": {
          "iopub.status.busy": "2023-12-28T13:51:26.630792Z",
          "iopub.execute_input": "2023-12-28T13:51:26.631148Z",
          "iopub.status.idle": "2023-12-28T13:51:26.637974Z",
          "shell.execute_reply.started": "2023-12-28T13:51:26.631120Z",
          "shell.execute_reply": "2023-12-28T13:51:26.636918Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "0R904mrbn1H3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "432e40f3-ce76-4a04-8e19-6add82521dca",
        "execution": {
          "iopub.status.busy": "2023-12-28T13:51:26.639313Z",
          "iopub.execute_input": "2023-12-28T13:51:26.639900Z",
          "iopub.status.idle": "2023-12-28T13:51:26.650201Z",
          "shell.execute_reply.started": "2023-12-28T13:51:26.639865Z",
          "shell.execute_reply": "2023-12-28T13:51:26.649332Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['summary', 'text'],\n    num_rows: 37519\n})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split the dataset"
      ],
      "metadata": {
        "id": "XIajFg6wiBFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_txt, validation_data_txt = dataset.train_test_split(test_size=0.3).values()"
      ],
      "metadata": {
        "id": "AEV4XmfdeV8_",
        "execution": {
          "iopub.status.busy": "2023-12-28T13:51:26.651233Z",
          "iopub.execute_input": "2023-12-28T13:51:26.651493Z",
          "iopub.status.idle": "2023-12-28T13:51:26.682271Z",
          "shell.execute_reply.started": "2023-12-28T13:51:26.651470Z",
          "shell.execute_reply": "2023-12-28T13:51:26.681571Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batch processing function for tokenization"
      ],
      "metadata": {
        "id": "EaYmEQ-MiUTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_max_length = 128\n",
        "encoder_max_length = 512\n",
        "\n",
        "def batch_tokenize_preprocess(batch, tokenizer, max_source_length, max_target_length):\n",
        "    #source, target = batch[\"document\"], batch[\"summary\"]\n",
        "    source, target = batch[\"text\"], batch[\"summary\"]\n",
        "    source_tokenized = tokenizer(\n",
        "        source, padding=\"max_length\", truncation=True, max_length=max_source_length\n",
        "    )\n",
        "    target_tokenized = tokenizer(\n",
        "        target, padding=\"max_length\", truncation=True, max_length=max_target_length\n",
        "    )\n",
        "\n",
        "    batch = {k: v for k, v in source_tokenized.items()}\n",
        "    # Ignore padding in the loss\n",
        "    batch[\"labels\"] = [\n",
        "        [-100 if token == tokenizer.pad_token_id else token for token in l]\n",
        "        for l in target_tokenized[\"input_ids\"]\n",
        "    ]\n",
        "    return batch\n",
        "\n",
        "train_data = train_data_txt.map(\n",
        "    lambda batch: batch_tokenize_preprocess(\n",
        "        batch, tokenizer, encoder_max_length, decoder_max_length\n",
        "    ),\n",
        "    batched=True,\n",
        "    remove_columns=train_data_txt.column_names,\n",
        ")\n",
        "\n",
        "validation_data = validation_data_txt.map(\n",
        "    lambda batch: batch_tokenize_preprocess(\n",
        "        batch, tokenizer, encoder_max_length, decoder_max_length\n",
        "    ),\n",
        "    batched=True,\n",
        "    remove_columns=validation_data_txt.column_names,\n",
        ")"
      ],
      "metadata": {
        "id": "PyksYNwxA4OM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "c6daba3253244d2dab9f758f4f29e18f",
            "18b3c2d494fc4990846b5b6c085ed7fd",
            "687afc222ab74f9f9ed5a4fcdf45c55e",
            "5f8bfc96b17e4dd594016bdab1c7f7c7",
            "8f174b40bd49437fa346913ecdbef04f",
            "006e19e4affd434e8305fe57f1a7c36c",
            "45b8503dcbda41df8927180b8ea25933",
            "aa8f5086e46b49998d8349b9e93844f2",
            "cf51a35edabb4effa7d4be1e13bc7994",
            "699b9f07558f405daed87fdd4b0677df",
            "b9b915c0f06c4b61a28b07618caad60e",
            "5ed206c55f3a4a338b51be38b89a0d6c",
            "87ac6aba356b4defba75d6fc82f3897d",
            "2ff3207c83e3423aafa823e8a1ae7834",
            "10daafbe8df648b5a271804d6be50a7c",
            "8913366bdfbc464885f221c88ac04de6",
            "44886bb02ca448d49451101437cc878a",
            "0dc587ca4451436998acd8ff5cb90717",
            "53f2d6d0aa21411fa9e3eec43dc85a66",
            "f86a47b6181544158836317b5188fb43",
            "a7bf0180c8e7460a81d7ad295ce97e44",
            "fa8d2aac8f4c481093afef2139c8f085",
            "d3970965af914cc885972650f633da10",
            "8c44808263434d8eb47c481b836f7948"
          ]
        },
        "outputId": "a4317db8-f85d-4d5f-9da2-c0992014b420",
        "execution": {
          "iopub.status.busy": "2023-12-28T13:51:26.683251Z",
          "iopub.execute_input": "2023-12-28T13:51:26.683517Z",
          "iopub.status.idle": "2023-12-28T13:52:30.971429Z",
          "shell.execute_reply.started": "2023-12-28T13:51:26.683493Z",
          "shell.execute_reply": "2023-12-28T13:52:30.970651Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/27 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3970965af914cc885972650f633da10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/12 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c44808263434d8eb47c481b836f7948"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Borrowed from https://github.com/huggingface/transformers/blob/master/examples/seq2seq/run_summarization.py\n",
        "\n",
        "nltk.download(\"punkt\", quiet=True)\n",
        "\n",
        "metric = datasets.load_metric(\"rouge\")\n",
        "\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    # Stripping leading and trailing whitespace\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [label.strip() for label in labels]\n",
        "\n",
        "    # Tokenization using NLTK's sent_tokenize and joining with newline characters\n",
        "    # RougeLSum expects newline after each sentence\n",
        "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
        "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    # Extracting Predictions and Labels:\n",
        "    preds, labels = eval_preds\n",
        "\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "    # Decoding Predictions and Labels\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    # Use the ROUGE metric to compute evaluation results\n",
        "    result = metric.compute(\n",
        "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
        "    )\n",
        "\n",
        "    # Extract specific ROUGE scores (mid.fmeasure) and convert them to percentages\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "\n",
        "    # Count non-pad tokens in each prediction to compute average length\n",
        "    prediction_lens = [\n",
        "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n",
        "    ]\n",
        "\n",
        "    # Compute the average length of the generated predictions\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "\n",
        "    # Round all values in the result dictionary to four decimal places\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "rpNCGl2sYl2p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "4e14f84140e64954a8ff6357447c88b7"
          ]
        },
        "outputId": "f567a50b-1210-4ea8-d125-e51feb9654cd",
        "execution": {
          "iopub.status.busy": "2023-12-28T13:52:30.972768Z",
          "iopub.execute_input": "2023-12-28T13:52:30.973539Z",
          "iopub.status.idle": "2023-12-28T13:52:31.518325Z",
          "shell.execute_reply.started": "2023-12-28T13:52:30.973503Z",
          "shell.execute_reply": "2023-12-28T13:52:31.517628Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e14f84140e64954a8ff6357447c88b7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "7JRk9xovmhr4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initlize the trainer"
      ],
      "metadata": {
        "id": "5ZmfmaZXniT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training arguments\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"results\",\n",
        "    num_train_epochs=5,  # demo\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    per_device_train_batch_size=4,  # demo\n",
        "    per_device_eval_batch_size=4,\n",
        "    seed=42,\n",
        "    learning_rate=5e-05,\n",
        "    warmup_steps=250,\n",
        "    weight_decay=0.1,\n",
        "    label_smoothing_factor=0.1,\n",
        "    predict_with_generate=True,\n",
        "    logging_dir=\"logs\",\n",
        "    logging_steps=50,\n",
        "    save_total_limit=3,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    optim=\"adamw_hf\",\n",
        "    adam_beta1 = 0.9,\n",
        "    adam_beta2= 0.999,\n",
        "    adam_epsilon= 1e-08,\n",
        ")\n",
        "\n",
        "# Initialize data collator for sequence-to-sequence task\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "# Initialize Seq2SeqTrainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=validation_data,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    )"
      ],
      "metadata": {
        "id": "6R9d7ELIpX9F",
        "execution": {
          "iopub.status.busy": "2023-12-28T13:52:31.519382Z",
          "iopub.execute_input": "2023-12-28T13:52:31.519673Z",
          "iopub.status.idle": "2023-12-28T13:52:37.805290Z",
          "shell.execute_reply.started": "2023-12-28T13:52:31.519648Z",
          "shell.execute_reply": "2023-12-28T13:52:37.804527Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### login in wandb for training"
      ],
      "metadata": {
        "id": "uy-LWL_OpnkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WANDB_INTEGRATION = True\n",
        "if WANDB_INTEGRATION:\n",
        "    import wandb\n",
        "\n",
        "    wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LD1ypa4PpnDF",
        "outputId": "6532e7bf-509f-4d57-d79f-69d320b305b9",
        "execution": {
          "iopub.status.busy": "2023-12-28T13:52:37.806370Z",
          "iopub.execute_input": "2023-12-28T13:52:37.806645Z",
          "iopub.status.idle": "2023-12-28T13:52:52.498840Z",
          "shell.execute_reply.started": "2023-12-28T13:52:37.806620Z",
          "shell.execute_reply": "2023-12-28T13:52:52.497765Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:",
          "output_type": "stream"
        },
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "  ········································\n"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start train model"
      ],
      "metadata": {
        "id": "maiUcSbunsvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#final\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2PbtK-jUl0Q7",
        "outputId": "a3c30384-75b3-44b7-cb6a-9e7bca9572b6",
        "execution": {
          "iopub.status.busy": "2023-12-28T13:52:52.499929Z",
          "iopub.execute_input": "2023-12-28T13:52:52.500535Z",
          "iopub.status.idle": "2023-12-28T16:18:12.751181Z",
          "shell.execute_reply.started": "2023-12-28T13:52:52.500506Z",
          "shell.execute_reply": "2023-12-28T16:18:12.750150Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maliashrafali770\u001b[0m (\u001b[33maliashraf123\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.16.1"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20231228_135252-6xpwlcyl</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/aliashraf123/huggingface/runs/6xpwlcyl' target=\"_blank\">snowy-aardvark-3</a></strong> to <a href='https://wandb.ai/aliashraf123/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/aliashraf123/huggingface' target=\"_blank\">https://wandb.ai/aliashraf123/huggingface</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/aliashraf123/huggingface/runs/6xpwlcyl' target=\"_blank\">https://wandb.ai/aliashraf123/huggingface/runs/6xpwlcyl</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "You're using a BarthezTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='16415' max='16415' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [16415/16415 2:24:43, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>4.051000</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>3.862700</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>3.793200</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>3.820200</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>3.844700</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>3.798300</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>3.861400</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>3.794700</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>3.798700</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>3.756000</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>3.773600</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>3.747900</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>3.694500</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>3.763700</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>3.738400</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>3.700500</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>3.745800</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>3.758100</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>3.784800</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>3.807200</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>3.706100</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>3.734300</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>3.680400</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>3.754400</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>3.804400</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>3.700200</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>3.743800</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>3.711000</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>3.709800</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>3.685600</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>3.683900</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>3.806800</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>3.729100</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>3.707700</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>3.714600</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>3.770700</td>\n    </tr>\n    <tr>\n      <td>1850</td>\n      <td>3.779900</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>3.807100</td>\n    </tr>\n    <tr>\n      <td>1950</td>\n      <td>3.661900</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>3.704800</td>\n    </tr>\n    <tr>\n      <td>2050</td>\n      <td>3.731700</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>3.711600</td>\n    </tr>\n    <tr>\n      <td>2150</td>\n      <td>3.793300</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>3.717900</td>\n    </tr>\n    <tr>\n      <td>2250</td>\n      <td>3.668300</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>3.685300</td>\n    </tr>\n    <tr>\n      <td>2350</td>\n      <td>3.678600</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>3.702800</td>\n    </tr>\n    <tr>\n      <td>2450</td>\n      <td>3.692800</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>3.747800</td>\n    </tr>\n    <tr>\n      <td>2550</td>\n      <td>3.720200</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>3.674800</td>\n    </tr>\n    <tr>\n      <td>2650</td>\n      <td>3.673200</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>3.756000</td>\n    </tr>\n    <tr>\n      <td>2750</td>\n      <td>3.706100</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>3.695500</td>\n    </tr>\n    <tr>\n      <td>2850</td>\n      <td>3.662000</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>3.634500</td>\n    </tr>\n    <tr>\n      <td>2950</td>\n      <td>3.748000</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>3.720100</td>\n    </tr>\n    <tr>\n      <td>3050</td>\n      <td>3.688600</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>3.657300</td>\n    </tr>\n    <tr>\n      <td>3150</td>\n      <td>3.691900</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>3.678500</td>\n    </tr>\n    <tr>\n      <td>3250</td>\n      <td>3.729200</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>3.660000</td>\n    </tr>\n    <tr>\n      <td>3350</td>\n      <td>3.507100</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>3.445000</td>\n    </tr>\n    <tr>\n      <td>3450</td>\n      <td>3.504500</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>3.538300</td>\n    </tr>\n    <tr>\n      <td>3550</td>\n      <td>3.469000</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>3.461900</td>\n    </tr>\n    <tr>\n      <td>3650</td>\n      <td>3.502500</td>\n    </tr>\n    <tr>\n      <td>3700</td>\n      <td>3.553300</td>\n    </tr>\n    <tr>\n      <td>3750</td>\n      <td>3.461200</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>3.545700</td>\n    </tr>\n    <tr>\n      <td>3850</td>\n      <td>3.534000</td>\n    </tr>\n    <tr>\n      <td>3900</td>\n      <td>3.426900</td>\n    </tr>\n    <tr>\n      <td>3950</td>\n      <td>3.494500</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>3.487500</td>\n    </tr>\n    <tr>\n      <td>4050</td>\n      <td>3.476800</td>\n    </tr>\n    <tr>\n      <td>4100</td>\n      <td>3.557400</td>\n    </tr>\n    <tr>\n      <td>4150</td>\n      <td>3.530800</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>3.555900</td>\n    </tr>\n    <tr>\n      <td>4250</td>\n      <td>3.482600</td>\n    </tr>\n    <tr>\n      <td>4300</td>\n      <td>3.490000</td>\n    </tr>\n    <tr>\n      <td>4350</td>\n      <td>3.521100</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>3.526200</td>\n    </tr>\n    <tr>\n      <td>4450</td>\n      <td>3.527200</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>3.458500</td>\n    </tr>\n    <tr>\n      <td>4550</td>\n      <td>3.497000</td>\n    </tr>\n    <tr>\n      <td>4600</td>\n      <td>3.535000</td>\n    </tr>\n    <tr>\n      <td>4650</td>\n      <td>3.547200</td>\n    </tr>\n    <tr>\n      <td>4700</td>\n      <td>3.523000</td>\n    </tr>\n    <tr>\n      <td>4750</td>\n      <td>3.484900</td>\n    </tr>\n    <tr>\n      <td>4800</td>\n      <td>3.479000</td>\n    </tr>\n    <tr>\n      <td>4850</td>\n      <td>3.480700</td>\n    </tr>\n    <tr>\n      <td>4900</td>\n      <td>3.498100</td>\n    </tr>\n    <tr>\n      <td>4950</td>\n      <td>3.477300</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>3.530100</td>\n    </tr>\n    <tr>\n      <td>5050</td>\n      <td>3.504300</td>\n    </tr>\n    <tr>\n      <td>5100</td>\n      <td>3.542900</td>\n    </tr>\n    <tr>\n      <td>5150</td>\n      <td>3.471800</td>\n    </tr>\n    <tr>\n      <td>5200</td>\n      <td>3.509200</td>\n    </tr>\n    <tr>\n      <td>5250</td>\n      <td>3.467200</td>\n    </tr>\n    <tr>\n      <td>5300</td>\n      <td>3.501400</td>\n    </tr>\n    <tr>\n      <td>5350</td>\n      <td>3.506500</td>\n    </tr>\n    <tr>\n      <td>5400</td>\n      <td>3.519200</td>\n    </tr>\n    <tr>\n      <td>5450</td>\n      <td>3.548900</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>3.525400</td>\n    </tr>\n    <tr>\n      <td>5550</td>\n      <td>3.498200</td>\n    </tr>\n    <tr>\n      <td>5600</td>\n      <td>3.467700</td>\n    </tr>\n    <tr>\n      <td>5650</td>\n      <td>3.437400</td>\n    </tr>\n    <tr>\n      <td>5700</td>\n      <td>3.491000</td>\n    </tr>\n    <tr>\n      <td>5750</td>\n      <td>3.494600</td>\n    </tr>\n    <tr>\n      <td>5800</td>\n      <td>3.527200</td>\n    </tr>\n    <tr>\n      <td>5850</td>\n      <td>3.533900</td>\n    </tr>\n    <tr>\n      <td>5900</td>\n      <td>3.526900</td>\n    </tr>\n    <tr>\n      <td>5950</td>\n      <td>3.482900</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>3.513900</td>\n    </tr>\n    <tr>\n      <td>6050</td>\n      <td>3.481300</td>\n    </tr>\n    <tr>\n      <td>6100</td>\n      <td>3.528100</td>\n    </tr>\n    <tr>\n      <td>6150</td>\n      <td>3.583700</td>\n    </tr>\n    <tr>\n      <td>6200</td>\n      <td>3.518100</td>\n    </tr>\n    <tr>\n      <td>6250</td>\n      <td>3.559800</td>\n    </tr>\n    <tr>\n      <td>6300</td>\n      <td>3.467500</td>\n    </tr>\n    <tr>\n      <td>6350</td>\n      <td>3.502900</td>\n    </tr>\n    <tr>\n      <td>6400</td>\n      <td>3.505700</td>\n    </tr>\n    <tr>\n      <td>6450</td>\n      <td>3.561200</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>3.490800</td>\n    </tr>\n    <tr>\n      <td>6550</td>\n      <td>3.492600</td>\n    </tr>\n    <tr>\n      <td>6600</td>\n      <td>3.330500</td>\n    </tr>\n    <tr>\n      <td>6650</td>\n      <td>3.346100</td>\n    </tr>\n    <tr>\n      <td>6700</td>\n      <td>3.309100</td>\n    </tr>\n    <tr>\n      <td>6750</td>\n      <td>3.346900</td>\n    </tr>\n    <tr>\n      <td>6800</td>\n      <td>3.369300</td>\n    </tr>\n    <tr>\n      <td>6850</td>\n      <td>3.315000</td>\n    </tr>\n    <tr>\n      <td>6900</td>\n      <td>3.304100</td>\n    </tr>\n    <tr>\n      <td>6950</td>\n      <td>3.323600</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>3.360300</td>\n    </tr>\n    <tr>\n      <td>7050</td>\n      <td>3.317700</td>\n    </tr>\n    <tr>\n      <td>7100</td>\n      <td>3.318900</td>\n    </tr>\n    <tr>\n      <td>7150</td>\n      <td>3.313700</td>\n    </tr>\n    <tr>\n      <td>7200</td>\n      <td>3.343300</td>\n    </tr>\n    <tr>\n      <td>7250</td>\n      <td>3.369800</td>\n    </tr>\n    <tr>\n      <td>7300</td>\n      <td>3.331600</td>\n    </tr>\n    <tr>\n      <td>7350</td>\n      <td>3.360900</td>\n    </tr>\n    <tr>\n      <td>7400</td>\n      <td>3.285000</td>\n    </tr>\n    <tr>\n      <td>7450</td>\n      <td>3.321000</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>3.318000</td>\n    </tr>\n    <tr>\n      <td>7550</td>\n      <td>3.333800</td>\n    </tr>\n    <tr>\n      <td>7600</td>\n      <td>3.342400</td>\n    </tr>\n    <tr>\n      <td>7650</td>\n      <td>3.413500</td>\n    </tr>\n    <tr>\n      <td>7700</td>\n      <td>3.350200</td>\n    </tr>\n    <tr>\n      <td>7750</td>\n      <td>3.356900</td>\n    </tr>\n    <tr>\n      <td>7800</td>\n      <td>3.306800</td>\n    </tr>\n    <tr>\n      <td>7850</td>\n      <td>3.378500</td>\n    </tr>\n    <tr>\n      <td>7900</td>\n      <td>3.324500</td>\n    </tr>\n    <tr>\n      <td>7950</td>\n      <td>3.368600</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>3.394200</td>\n    </tr>\n    <tr>\n      <td>8050</td>\n      <td>3.412500</td>\n    </tr>\n    <tr>\n      <td>8100</td>\n      <td>3.287100</td>\n    </tr>\n    <tr>\n      <td>8150</td>\n      <td>3.377600</td>\n    </tr>\n    <tr>\n      <td>8200</td>\n      <td>3.326100</td>\n    </tr>\n    <tr>\n      <td>8250</td>\n      <td>3.375500</td>\n    </tr>\n    <tr>\n      <td>8300</td>\n      <td>3.323000</td>\n    </tr>\n    <tr>\n      <td>8350</td>\n      <td>3.344500</td>\n    </tr>\n    <tr>\n      <td>8400</td>\n      <td>3.364600</td>\n    </tr>\n    <tr>\n      <td>8450</td>\n      <td>3.323900</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>3.362700</td>\n    </tr>\n    <tr>\n      <td>8550</td>\n      <td>3.328400</td>\n    </tr>\n    <tr>\n      <td>8600</td>\n      <td>3.361300</td>\n    </tr>\n    <tr>\n      <td>8650</td>\n      <td>3.347000</td>\n    </tr>\n    <tr>\n      <td>8700</td>\n      <td>3.364000</td>\n    </tr>\n    <tr>\n      <td>8750</td>\n      <td>3.352700</td>\n    </tr>\n    <tr>\n      <td>8800</td>\n      <td>3.377300</td>\n    </tr>\n    <tr>\n      <td>8850</td>\n      <td>3.401000</td>\n    </tr>\n    <tr>\n      <td>8900</td>\n      <td>3.392000</td>\n    </tr>\n    <tr>\n      <td>8950</td>\n      <td>3.442700</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>3.359200</td>\n    </tr>\n    <tr>\n      <td>9050</td>\n      <td>3.377400</td>\n    </tr>\n    <tr>\n      <td>9100</td>\n      <td>3.339200</td>\n    </tr>\n    <tr>\n      <td>9150</td>\n      <td>3.411100</td>\n    </tr>\n    <tr>\n      <td>9200</td>\n      <td>3.402400</td>\n    </tr>\n    <tr>\n      <td>9250</td>\n      <td>3.380600</td>\n    </tr>\n    <tr>\n      <td>9300</td>\n      <td>3.349800</td>\n    </tr>\n    <tr>\n      <td>9350</td>\n      <td>3.384500</td>\n    </tr>\n    <tr>\n      <td>9400</td>\n      <td>3.321800</td>\n    </tr>\n    <tr>\n      <td>9450</td>\n      <td>3.409800</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>3.349600</td>\n    </tr>\n    <tr>\n      <td>9550</td>\n      <td>3.356000</td>\n    </tr>\n    <tr>\n      <td>9600</td>\n      <td>3.365800</td>\n    </tr>\n    <tr>\n      <td>9650</td>\n      <td>3.332000</td>\n    </tr>\n    <tr>\n      <td>9700</td>\n      <td>3.320100</td>\n    </tr>\n    <tr>\n      <td>9750</td>\n      <td>3.357300</td>\n    </tr>\n    <tr>\n      <td>9800</td>\n      <td>3.361500</td>\n    </tr>\n    <tr>\n      <td>9850</td>\n      <td>3.387300</td>\n    </tr>\n    <tr>\n      <td>9900</td>\n      <td>3.218300</td>\n    </tr>\n    <tr>\n      <td>9950</td>\n      <td>3.208100</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>3.188400</td>\n    </tr>\n    <tr>\n      <td>10050</td>\n      <td>3.172600</td>\n    </tr>\n    <tr>\n      <td>10100</td>\n      <td>3.217000</td>\n    </tr>\n    <tr>\n      <td>10150</td>\n      <td>3.207800</td>\n    </tr>\n    <tr>\n      <td>10200</td>\n      <td>3.226800</td>\n    </tr>\n    <tr>\n      <td>10250</td>\n      <td>3.237800</td>\n    </tr>\n    <tr>\n      <td>10300</td>\n      <td>3.244000</td>\n    </tr>\n    <tr>\n      <td>10350</td>\n      <td>3.234900</td>\n    </tr>\n    <tr>\n      <td>10400</td>\n      <td>3.191700</td>\n    </tr>\n    <tr>\n      <td>10450</td>\n      <td>3.230200</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>3.264400</td>\n    </tr>\n    <tr>\n      <td>10550</td>\n      <td>3.224300</td>\n    </tr>\n    <tr>\n      <td>10600</td>\n      <td>3.223400</td>\n    </tr>\n    <tr>\n      <td>10650</td>\n      <td>3.228500</td>\n    </tr>\n    <tr>\n      <td>10700</td>\n      <td>3.262900</td>\n    </tr>\n    <tr>\n      <td>10750</td>\n      <td>3.218500</td>\n    </tr>\n    <tr>\n      <td>10800</td>\n      <td>3.198300</td>\n    </tr>\n    <tr>\n      <td>10850</td>\n      <td>3.241200</td>\n    </tr>\n    <tr>\n      <td>10900</td>\n      <td>3.231100</td>\n    </tr>\n    <tr>\n      <td>10950</td>\n      <td>3.266200</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>3.215700</td>\n    </tr>\n    <tr>\n      <td>11050</td>\n      <td>3.252300</td>\n    </tr>\n    <tr>\n      <td>11100</td>\n      <td>3.242700</td>\n    </tr>\n    <tr>\n      <td>11150</td>\n      <td>3.201500</td>\n    </tr>\n    <tr>\n      <td>11200</td>\n      <td>3.236900</td>\n    </tr>\n    <tr>\n      <td>11250</td>\n      <td>3.231300</td>\n    </tr>\n    <tr>\n      <td>11300</td>\n      <td>3.214300</td>\n    </tr>\n    <tr>\n      <td>11350</td>\n      <td>3.247200</td>\n    </tr>\n    <tr>\n      <td>11400</td>\n      <td>3.193800</td>\n    </tr>\n    <tr>\n      <td>11450</td>\n      <td>3.221800</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>3.204600</td>\n    </tr>\n    <tr>\n      <td>11550</td>\n      <td>3.253600</td>\n    </tr>\n    <tr>\n      <td>11600</td>\n      <td>3.257100</td>\n    </tr>\n    <tr>\n      <td>11650</td>\n      <td>3.235200</td>\n    </tr>\n    <tr>\n      <td>11700</td>\n      <td>3.218700</td>\n    </tr>\n    <tr>\n      <td>11750</td>\n      <td>3.244100</td>\n    </tr>\n    <tr>\n      <td>11800</td>\n      <td>3.286700</td>\n    </tr>\n    <tr>\n      <td>11850</td>\n      <td>3.245300</td>\n    </tr>\n    <tr>\n      <td>11900</td>\n      <td>3.235700</td>\n    </tr>\n    <tr>\n      <td>11950</td>\n      <td>3.269600</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>3.264000</td>\n    </tr>\n    <tr>\n      <td>12050</td>\n      <td>3.213000</td>\n    </tr>\n    <tr>\n      <td>12100</td>\n      <td>3.263700</td>\n    </tr>\n    <tr>\n      <td>12150</td>\n      <td>3.226200</td>\n    </tr>\n    <tr>\n      <td>12200</td>\n      <td>3.261400</td>\n    </tr>\n    <tr>\n      <td>12250</td>\n      <td>3.306200</td>\n    </tr>\n    <tr>\n      <td>12300</td>\n      <td>3.237300</td>\n    </tr>\n    <tr>\n      <td>12350</td>\n      <td>3.221000</td>\n    </tr>\n    <tr>\n      <td>12400</td>\n      <td>3.298200</td>\n    </tr>\n    <tr>\n      <td>12450</td>\n      <td>3.217200</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>3.246700</td>\n    </tr>\n    <tr>\n      <td>12550</td>\n      <td>3.247100</td>\n    </tr>\n    <tr>\n      <td>12600</td>\n      <td>3.261600</td>\n    </tr>\n    <tr>\n      <td>12650</td>\n      <td>3.248800</td>\n    </tr>\n    <tr>\n      <td>12700</td>\n      <td>3.225900</td>\n    </tr>\n    <tr>\n      <td>12750</td>\n      <td>3.225600</td>\n    </tr>\n    <tr>\n      <td>12800</td>\n      <td>3.267600</td>\n    </tr>\n    <tr>\n      <td>12850</td>\n      <td>3.230100</td>\n    </tr>\n    <tr>\n      <td>12900</td>\n      <td>3.299900</td>\n    </tr>\n    <tr>\n      <td>12950</td>\n      <td>3.296300</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>3.250000</td>\n    </tr>\n    <tr>\n      <td>13050</td>\n      <td>3.281200</td>\n    </tr>\n    <tr>\n      <td>13100</td>\n      <td>3.242200</td>\n    </tr>\n    <tr>\n      <td>13150</td>\n      <td>3.274400</td>\n    </tr>\n    <tr>\n      <td>13200</td>\n      <td>3.196100</td>\n    </tr>\n    <tr>\n      <td>13250</td>\n      <td>3.183600</td>\n    </tr>\n    <tr>\n      <td>13300</td>\n      <td>3.106200</td>\n    </tr>\n    <tr>\n      <td>13350</td>\n      <td>3.125900</td>\n    </tr>\n    <tr>\n      <td>13400</td>\n      <td>3.169800</td>\n    </tr>\n    <tr>\n      <td>13450</td>\n      <td>3.191200</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>3.140600</td>\n    </tr>\n    <tr>\n      <td>13550</td>\n      <td>3.152900</td>\n    </tr>\n    <tr>\n      <td>13600</td>\n      <td>3.110400</td>\n    </tr>\n    <tr>\n      <td>13650</td>\n      <td>3.124200</td>\n    </tr>\n    <tr>\n      <td>13700</td>\n      <td>3.169600</td>\n    </tr>\n    <tr>\n      <td>13750</td>\n      <td>3.175200</td>\n    </tr>\n    <tr>\n      <td>13800</td>\n      <td>3.200700</td>\n    </tr>\n    <tr>\n      <td>13850</td>\n      <td>3.156600</td>\n    </tr>\n    <tr>\n      <td>13900</td>\n      <td>3.152300</td>\n    </tr>\n    <tr>\n      <td>13950</td>\n      <td>3.165600</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>3.137400</td>\n    </tr>\n    <tr>\n      <td>14050</td>\n      <td>3.184300</td>\n    </tr>\n    <tr>\n      <td>14100</td>\n      <td>3.116000</td>\n    </tr>\n    <tr>\n      <td>14150</td>\n      <td>3.139000</td>\n    </tr>\n    <tr>\n      <td>14200</td>\n      <td>3.178300</td>\n    </tr>\n    <tr>\n      <td>14250</td>\n      <td>3.141200</td>\n    </tr>\n    <tr>\n      <td>14300</td>\n      <td>3.145500</td>\n    </tr>\n    <tr>\n      <td>14350</td>\n      <td>3.184400</td>\n    </tr>\n    <tr>\n      <td>14400</td>\n      <td>3.149800</td>\n    </tr>\n    <tr>\n      <td>14450</td>\n      <td>3.169600</td>\n    </tr>\n    <tr>\n      <td>14500</td>\n      <td>3.082500</td>\n    </tr>\n    <tr>\n      <td>14550</td>\n      <td>3.121700</td>\n    </tr>\n    <tr>\n      <td>14600</td>\n      <td>3.198200</td>\n    </tr>\n    <tr>\n      <td>14650</td>\n      <td>3.156800</td>\n    </tr>\n    <tr>\n      <td>14700</td>\n      <td>3.164800</td>\n    </tr>\n    <tr>\n      <td>14750</td>\n      <td>3.157000</td>\n    </tr>\n    <tr>\n      <td>14800</td>\n      <td>3.188500</td>\n    </tr>\n    <tr>\n      <td>14850</td>\n      <td>3.131700</td>\n    </tr>\n    <tr>\n      <td>14900</td>\n      <td>3.179100</td>\n    </tr>\n    <tr>\n      <td>14950</td>\n      <td>3.207900</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>3.141600</td>\n    </tr>\n    <tr>\n      <td>15050</td>\n      <td>3.135100</td>\n    </tr>\n    <tr>\n      <td>15100</td>\n      <td>3.193200</td>\n    </tr>\n    <tr>\n      <td>15150</td>\n      <td>3.183200</td>\n    </tr>\n    <tr>\n      <td>15200</td>\n      <td>3.186100</td>\n    </tr>\n    <tr>\n      <td>15250</td>\n      <td>3.086000</td>\n    </tr>\n    <tr>\n      <td>15300</td>\n      <td>3.157900</td>\n    </tr>\n    <tr>\n      <td>15350</td>\n      <td>3.167800</td>\n    </tr>\n    <tr>\n      <td>15400</td>\n      <td>3.120800</td>\n    </tr>\n    <tr>\n      <td>15450</td>\n      <td>3.198700</td>\n    </tr>\n    <tr>\n      <td>15500</td>\n      <td>3.137900</td>\n    </tr>\n    <tr>\n      <td>15550</td>\n      <td>3.165300</td>\n    </tr>\n    <tr>\n      <td>15600</td>\n      <td>3.125000</td>\n    </tr>\n    <tr>\n      <td>15650</td>\n      <td>3.159400</td>\n    </tr>\n    <tr>\n      <td>15700</td>\n      <td>3.185200</td>\n    </tr>\n    <tr>\n      <td>15750</td>\n      <td>3.201200</td>\n    </tr>\n    <tr>\n      <td>15800</td>\n      <td>3.165800</td>\n    </tr>\n    <tr>\n      <td>15850</td>\n      <td>3.119700</td>\n    </tr>\n    <tr>\n      <td>15900</td>\n      <td>3.191400</td>\n    </tr>\n    <tr>\n      <td>15950</td>\n      <td>3.188400</td>\n    </tr>\n    <tr>\n      <td>16000</td>\n      <td>3.169800</td>\n    </tr>\n    <tr>\n      <td>16050</td>\n      <td>3.167200</td>\n    </tr>\n    <tr>\n      <td>16100</td>\n      <td>3.168600</td>\n    </tr>\n    <tr>\n      <td>16150</td>\n      <td>3.188000</td>\n    </tr>\n    <tr>\n      <td>16200</td>\n      <td>3.161200</td>\n    </tr>\n    <tr>\n      <td>16250</td>\n      <td>3.178500</td>\n    </tr>\n    <tr>\n      <td>16300</td>\n      <td>3.132800</td>\n    </tr>\n    <tr>\n      <td>16350</td>\n      <td>3.199200</td>\n    </tr>\n    <tr>\n      <td>16400</td>\n      <td>3.128300</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "execution_count": 21,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainOutput(global_step=16415, training_loss=3.399114825236808, metrics={'train_runtime': 8719.933, 'train_samples_per_second': 15.059, 'train_steps_per_second': 1.882, 'total_flos': 4.003501075070976e+16, 'train_loss': 3.399114825236808, 'epoch': 5.0})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the model"
      ],
      "metadata": {
        "id": "A_RZlwyq7ABd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = 'rtsumm/kaggle/working/arabaarization/'\n",
        "trainer.save_model(model_dir + 'model2')"
      ],
      "metadata": {
        "id": "5lpxQglv7uOz",
        "execution": {
          "iopub.status.busy": "2023-12-28T16:19:43.490982Z",
          "iopub.execute_input": "2023-12-28T16:19:43.491375Z",
          "iopub.status.idle": "2023-12-28T16:19:44.683267Z",
          "shell.execute_reply.started": "2023-12-28T16:19:43.491345Z",
          "shell.execute_reply": "2023-12-28T16:19:44.682114Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the fine-tuned model to Google Drive\n",
        "model.save_pretrained(\"rtsumm/kaggle/working/arabaarization/arabartsummarization/pretrained\")"
      ],
      "metadata": {
        "id": "GJWeJ96jPkI_",
        "execution": {
          "iopub.status.busy": "2023-12-28T16:20:47.166959Z",
          "iopub.execute_input": "2023-12-28T16:20:47.167749Z",
          "iopub.status.idle": "2023-12-28T16:20:48.331326Z",
          "shell.execute_reply.started": "2023-12-28T16:20:47.167702Z",
          "shell.execute_reply": "2023-12-28T16:20:48.330186Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the model"
      ],
      "metadata": {
        "id": "NMX8w2Yx7HEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "9SJ6P34JtiBD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "4f9d671f-3d37-48bd-f464-d5d7a74519fb",
        "execution": {
          "iopub.status.busy": "2023-12-28T16:20:52.514833Z",
          "iopub.execute_input": "2023-12-28T16:20:52.515457Z",
          "iopub.status.idle": "2023-12-28T16:36:47.987503Z",
          "shell.execute_reply.started": "2023-12-28T16:20:52.515427Z",
          "shell.execute_reply": "2023-12-28T16:36:47.986338Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='1407' max='1407' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1407/1407 15:47]\n    </div>\n    "
          },
          "metadata": {}
        },
        {
          "execution_count": 26,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'eval_loss': 3.4821231365203857,\n 'eval_rouge1': 2.3202,\n 'eval_rouge2': 0.0977,\n 'eval_rougeL': 2.3288,\n 'eval_rougeLsum': 2.3113,\n 'eval_gen_len': 19.6799,\n 'eval_runtime': 955.4586,\n 'eval_samples_per_second': 11.781,\n 'eval_steps_per_second': 1.473,\n 'epoch': 5.0}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(test_samples, model):\n",
        "    inputs = tokenizer(\n",
        "        #test_samples[\"document\"],\n",
        "        #test_samples[\"text\"],\n",
        "        test_samples,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=encoder_max_length,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    # Move the input tensors to the device where the model is located\n",
        "    input_ids = inputs.input_ids.to(model.device)\n",
        "    attention_mask = inputs.attention_mask.to(model.device)\n",
        "\n",
        "    # Generate summaries using the model\n",
        "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # Decode the generated output sequences into human-readable text\n",
        "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "    return outputs, output_str"
      ],
      "metadata": {
        "id": "3ii7dOHC7SwO",
        "execution": {
          "iopub.status.busy": "2023-12-28T17:20:44.333259Z",
          "iopub.execute_input": "2023-12-28T17:20:44.333694Z",
          "iopub.status.idle": "2023-12-28T17:20:44.342118Z",
          "shell.execute_reply.started": "2023-12-28T17:20:44.333661Z",
          "shell.execute_reply": "2023-12-28T17:20:44.340962Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load a test dataset"
      ],
      "metadata": {
        "id": "2cBXROHPlrvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testDataset = datasets.load_dataset(\"csebuetnlp/xlsum\", name=\"arabic\", split=\"test\")\n",
        "\n",
        "df = pd.DataFrame(testDataset)\n",
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T17:33:11.630212Z",
          "iopub.execute_input": "2023-12-28T17:33:11.630961Z",
          "iopub.status.idle": "2023-12-28T17:33:12.792691Z",
          "shell.execute_reply.started": "2023-12-28T17:33:11.630926Z",
          "shell.execute_reply": "2023-12-28T17:33:12.791257Z"
        },
        "trusted": true,
        "id": "sBfDMkxglrvn",
        "outputId": "63f631fb-79ab-4f92-e10c-f0543ca1fe81"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 35,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                               id  \\\n0      130806_nidhal_hassan_trial   \n1   160129_germany_asylum_seekers   \n2  130729_syria_homs_area_retaken   \n3   140517_arsenal_fa_cup_winners   \n4          140722_iraq_minorities   \n\n                                                 url  \\\n0  https://www.bbc.com/arabic/worldnews/2013/08/1...   \n1  https://www.bbc.com/arabic/worldnews/2016/01/1...   \n2  https://www.bbc.com/arabic/middleeast/2013/07/...   \n3  https://www.bbc.com/arabic/sports/2014/05/1405...   \n4  https://www.bbc.com/arabic/middleeast/2014/07/...   \n\n                                               title  \\\n0            نضال حسن يمثل أمام محكمة عسكرية أمريكية   \n1  ألمانيا تسعى للحد من الهجرة بإعلان الجزائر وتو...   \n2  الخالدية : التليفزيون السوري يعلن استعادة الجي...   \n3                     الارسنال يتوج بلقب كأس انكلترا   \n4                      العراق: الأقليات في سهل نينوى   \n\n                                             summary  \\\n0  تنظر محكمة عسكرية أمريكية في وقت لاحق من اليوم...   \n1  كشفت ألمانيا النقاب عن خطط لإضافة الجزائر والم...   \n2  قال التليفزيون السوري إن قوات الحكومة استعادت ...   \n3  توج فريق الارسنال ببطولة كأس انجلترا لكرة القد...   \n4  يوضع الصراع في العراق غالبا في إطار صراع بين ا...   \n\n                                                text  \n0  نضال حسن واعترف نضال حسن، الذي يدافع عن نفسه، ...  \n1  ألمانيا تواجه مصاعب في التعامل مع الأعداد المت...  \n2  وأكدت وسائل الإعلام السورية أن الجيش \"استعاد ا...  \n3  وفاجأ هال سيتي الحضور بمباغتة الارسنال بهدفين ...  \n4  معبد يزيدي في سهول محافظة نينوى يعيش المسيحيون...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>url</th>\n      <th>title</th>\n      <th>summary</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>130806_nidhal_hassan_trial</td>\n      <td>https://www.bbc.com/arabic/worldnews/2013/08/1...</td>\n      <td>نضال حسن يمثل أمام محكمة عسكرية أمريكية</td>\n      <td>تنظر محكمة عسكرية أمريكية في وقت لاحق من اليوم...</td>\n      <td>نضال حسن واعترف نضال حسن، الذي يدافع عن نفسه، ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>160129_germany_asylum_seekers</td>\n      <td>https://www.bbc.com/arabic/worldnews/2016/01/1...</td>\n      <td>ألمانيا تسعى للحد من الهجرة بإعلان الجزائر وتو...</td>\n      <td>كشفت ألمانيا النقاب عن خطط لإضافة الجزائر والم...</td>\n      <td>ألمانيا تواجه مصاعب في التعامل مع الأعداد المت...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>130729_syria_homs_area_retaken</td>\n      <td>https://www.bbc.com/arabic/middleeast/2013/07/...</td>\n      <td>الخالدية : التليفزيون السوري يعلن استعادة الجي...</td>\n      <td>قال التليفزيون السوري إن قوات الحكومة استعادت ...</td>\n      <td>وأكدت وسائل الإعلام السورية أن الجيش \"استعاد ا...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>140517_arsenal_fa_cup_winners</td>\n      <td>https://www.bbc.com/arabic/sports/2014/05/1405...</td>\n      <td>الارسنال يتوج بلقب كأس انكلترا</td>\n      <td>توج فريق الارسنال ببطولة كأس انجلترا لكرة القد...</td>\n      <td>وفاجأ هال سيتي الحضور بمباغتة الارسنال بهدفين ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>140722_iraq_minorities</td>\n      <td>https://www.bbc.com/arabic/middleeast/2014/07/...</td>\n      <td>العراق: الأقليات في سهل نينوى</td>\n      <td>يوضع الصراع في العراق غالبا في إطار صراع بين ا...</td>\n      <td>معبد يزيدي في سهول محافظة نينوى يعيش المسيحيون...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get a rouge score for 40 row from test dataset"
      ],
      "metadata": {
        "id": "faBbNL4jlrvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testSource = testDataset['text'][0:40]\n",
        "targetSource = testDataset['summary'][0:40]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T17:35:51.933395Z",
          "iopub.execute_input": "2023-12-28T17:35:51.934190Z",
          "iopub.status.idle": "2023-12-28T17:35:52.026540Z",
          "shell.execute_reply.started": "2023-12-28T17:35:51.934154Z",
          "shell.execute_reply": "2023-12-28T17:35:52.025544Z"
        },
        "trusted": true,
        "id": "0kOkNViblrvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summaries_after_tuning = generate_summary(testSource , model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T17:36:00.270190Z",
          "iopub.execute_input": "2023-12-28T17:36:00.270925Z",
          "iopub.status.idle": "2023-12-28T17:36:02.330968Z",
          "shell.execute_reply.started": "2023-12-28T17:36:00.270895Z",
          "shell.execute_reply": "2023-12-28T17:36:02.329951Z"
        },
        "trusted": true,
        "id": "6sqRy-HHlrvn",
        "outputId": "6e4bb402-92a0-45b2-f705-e8b2935c74c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_rouge_scores(reference_summaries, generated_summaries):\n",
        "    rouge = Rouge()\n",
        "    # Convert the input lists to strings\n",
        "    reference_summaries = [str(summary) for summary in reference_summaries]\n",
        "    generated_summaries = [str(summary) for summary in generated_summaries]\n",
        "\n",
        "    scores = rouge.get_scores(generated_summaries, reference_summaries, avg=True)\n",
        "    return scores\n",
        "\n",
        "rouge_scores = calculate_rouge_scores(targetSource, summaries_after_tuning[1])\n",
        "print(\"ROUGE Scores:\", rouge_scores)"
      ],
      "metadata": {
        "id": "J-kDaclzvAAo",
        "execution": {
          "iopub.status.busy": "2023-12-28T17:39:05.617591Z",
          "iopub.execute_input": "2023-12-28T17:39:05.618307Z",
          "iopub.status.idle": "2023-12-28T17:39:05.654273Z",
          "shell.execute_reply.started": "2023-12-28T17:39:05.618273Z",
          "shell.execute_reply": "2023-12-28T17:39:05.653297Z"
        },
        "trusted": true,
        "outputId": "7ca8260e-60d7-4155-cb6e-3d6b4d276695"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "ROUGE Scores: {'rouge-1': {'r': 0.24741749073764413, 'p': 0.36122868553015625, 'f': 0.28819034162831875}, 'rouge-2': {'r': 0.11422120115460718, 'p': 0.171666076978577, 'f': 0.1343900924253511}, 'rouge-l': {'r': 0.22742818789489294, 'p': 0.33283126799670926, 'f': 0.2654852832561154}}\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test with a text"
      ],
      "metadata": {
        "id": "4A552jWHlrvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"شهدت مدينة طرابلس، مساء أمس الأربعاء، احتجاجات شعبية وأعمال شغب لليوم الثالث على التوالي، وذلك بسبب تردي الوضع المعيشي والاقتصادي. واندلعت مواجهات عنيفة وعمليات كر وفر ما بين الجيش اللبناني والمحتجين استمرت لساعات، إثر محاولة فتح الطرقات المقطوعة، ما أدى إلى إصابة العشرات من الطرفين.\"\n",
        "print(\"text before summerize: \\n\" , text)\n",
        "\n",
        "result = generate_summary(text , model)\n",
        "print(\"text after summerize: \\n\" , result[1])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T17:50:56.154154Z",
          "iopub.execute_input": "2023-12-28T17:50:56.154507Z",
          "iopub.status.idle": "2023-12-28T17:50:56.445514Z",
          "shell.execute_reply.started": "2023-12-28T17:50:56.154481Z",
          "shell.execute_reply": "2023-12-28T17:50:56.443897Z"
        },
        "trusted": true,
        "id": "PDgEWPKulrvo",
        "outputId": "aea2b8e5-02dc-4ec2-9d54-927f11070660"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "text before summerize: \n شهدت مدينة طرابلس، مساء أمس الأربعاء، احتجاجات شعبية وأعمال شغب لليوم الثالث على التوالي، وذلك بسبب تردي الوضع المعيشي والاقتصادي. واندلعت مواجهات عنيفة وعمليات كر وفر ما بين الجيش اللبناني والمحتجين استمرت لساعات، إثر محاولة فتح الطرقات المقطوعة، ما أدى إلى إصابة العشرات من الطرفين.\ntext after summerize: \n ['تجددت الاشتباكات في مدينة طرابلس اللبنانية بين الجيش اللبناني والمحتجين لليوم الثالث على التوالي']\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}